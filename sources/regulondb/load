#!/usr/bin/env python3

from yome import Session
from yome.load import load_knowledgebase
from yome.util import apply_keyword, html_to_text

import pandas as pd
import json
from os.path import dirname, realpath, join
import re
import gzip

directory = realpath(dirname(__file__))

# Load data
df = pd.read_table(join(directory, 'network_tf_gene.txt'), sep='\t',
                   header=None, skiprows=34, index_col=False,
                   names=['tf', 'target', 'effect', 'evidence', 'type'])

# Split complex
replace ={
    'BCCP': ['accB'],
    'DinJ-YafQ': ['dinJ', 'yafQ'],
    'Dan': ['ttdR'],
    'H-NS': ['hns'],
    'HU': ['hupA', 'hupB'],
    'IHF': ['ihfA', 'ihfB'],
    'MazE-MazF': ['mazE', 'mazF'],
    'RcsB-BglJ': ['rcsB', 'bglJ'],
    'RelB-RelE': ['relB', 'relE'],
    'FlhDC': ['flhD', 'flhC'],
    'GadE-RcsB': ['gadE', 'rcsB'],
    'GatR': [], # 'gatR_1', 'gatR_2'], ... pseudogenes so skip
    'GutR': ['srlR'],
    'HigB-HigA': ['higB', 'higA'],
    'HipAB': ['hipA', 'hipB'],
    'MatA': ['ecpR'],
    'NtrC': ['glnG'],
    'RcsAB': ['rcsA', 'rcsB'],
    'YedW': ['hprR'],
    'YefM-YoeB': ['yefM', 'yoeB'],
    'YehT': ['btsR'],
    'YqjI': ['nfeR'],
}
def change(row, new):
    row.tf = new
    return row
for current, new_list in replace.items():
    for new in new_list:
        new_rows = df.loc[df.tf == current].apply(lambda row: change(row, new),
                                                  axis=1)
        df = df.append(new_rows, ignore_index=True)
    df = df.loc[df.tf != current]

# Load EcoCyc to get locus_tags
with gzip.open(join(directory, '..', 'ecocyc', 'results.json.gz'), 'rt') as f:
    results = json.load(f)
name_dict = {x['name']: x['b_number'] for x in results
             if 'b_number' in x}

df['primary_name'] = df.tf.apply(lambda x: (x[0].lower() + x[1:] if len(x) == 4
                                            else x.lower()))
df['locus_tag'] = df.primary_name.apply(lambda x: name_dict[x])

# Drop self-regulation, e.g. yeiL / yeiL
df = df[df.primary_name != df.target]

df['is_strong'] = df['type'].str.strip() == 'Strong'
strong_evidence = df.groupby('locus_tag').is_strong.agg(any).reset_index()
final_df = pd.DataFrame(strong_evidence).merge(
    df[['locus_tag', 'primary_name']].drop_duplicates(),
    left_on='locus_tag', right_on='locus_tag'
)

# final_df.loc[final_df.is_strong, 'annotation_quality'] = 'high'
# final_df.loc[~final_df.is_strong, 'annotation_quality'] = 'low'

# try calling all high to see if that better matches manual cases
final_df['annotation_quality'] = 'high'

# Load knowledgebase
session = Session()
load_knowledgebase(session, final_df, 'RegulonDB',
                   locus_id_column='locus_tag',
                   primary_name_column='primary_name',
                   synonyms_column=None,
                   feature_columns=[],
                   annotation_quality_column='annotation_quality')
session.close()

print()
print('RegulonDB')
print(final_df.annotation_quality.value_counts())
